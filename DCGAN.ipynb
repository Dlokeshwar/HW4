{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f218b021-b638-49e5-a207-9274421ec051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.11/site-packages (0.20.0)\n",
      "Requirement already satisfied: matplotlib in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (3.7.2)\n",
      "Requirement already satisfied: scipy in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /software/slurm/spackages/linux-rocky8-x86_64/gcc-12.2.0/anaconda3-2023.09-0-3mhml42fa64byxqyd5fig5tbih625dp2/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if not already installed\n",
    "!pip install torch torchvision matplotlib scipy numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08bf6929-e8f0-4bab-9231-65755c9033d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load and preprocess CIFAR-10 dataset\n",
    "def preprocess_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(64),  # Resize to 64x64\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])  # Normalize to [-1, 1]\n",
    "    ])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = preprocess_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c31b249-bb9f-4f79-b613-ac9efa414f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, text_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        input_dim = noise_dim + text_dim\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4 * 4 * 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (512, 4, 4)),\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, noise, text):\n",
    "        x = torch.cat((noise, text), dim=1)\n",
    "        return self.main(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438c2397-eeab-4623-87ed-a69bbe57f871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, text_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.text_embed = nn.Sequential(\n",
    "            nn.Linear(text_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (256, 1, 1))\n",
    "        )\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=2, padding=2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(512 + 256, 512, kernel_size=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 4 * 4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, image, text):\n",
    "        text_emb = self.text_embed(text).expand(-1, -1, 4, 4)\n",
    "        image_features = self.main(image)\n",
    "        combined = torch.cat((image_features, text_emb), dim=1)\n",
    "        return self.final(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a35d29-b959-4828-b301-4906f47c2e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(generator, discriminator, dataloader, epochs, noise_dim, text_dim, device):\n",
    "    # Optimizers and loss\n",
    "    gen_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            # Labels\n",
    "            real_labels = torch.full((batch_size, 1), 0.9, device=device)\n",
    "            fake_labels = torch.full((batch_size, 1), 0.1, device=device)\n",
    "\n",
    "\n",
    "            # Train Discriminator\n",
    "            noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "            text = torch.randn(batch_size, text_dim).to(device)\n",
    "            fake_images = generator(noise, text)\n",
    "\n",
    "            disc_real = discriminator(images, text)\n",
    "            disc_fake = discriminator(fake_images.detach(), text)\n",
    "\n",
    "            disc_loss_real = criterion(disc_real, real_labels)\n",
    "            disc_loss_fake = criterion(disc_fake, fake_labels)\n",
    "            disc_loss = disc_loss_real + disc_loss_fake\n",
    "\n",
    "            disc_optimizer.zero_grad()\n",
    "            disc_loss.backward()\n",
    "            disc_optimizer.step()\n",
    "\n",
    "            # Train Generator\n",
    "            fake_images = generator(noise, text)\n",
    "            disc_fake = discriminator(fake_images, text)\n",
    "            gen_loss = criterion(disc_fake, real_labels)\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Gen Loss: {gen_loss.item()} | Disc Loss: {disc_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3922f3ab-18bc-46f1-b447-e0acf3e26778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "import numpy as np\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "# Inception Score\n",
    "def inception_score(images, splits=10):\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).eval().to(images.device)\n",
    "    images_resized = torch.nn.functional.interpolate(images, size=(299, 299), mode='bilinear')\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for img_batch in torch.split(images_resized, 32):\n",
    "            pred = inception_model(img_batch)\n",
    "            preds.append(torch.nn.functional.softmax(pred, dim=1))\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "\n",
    "    split_scores = []\n",
    "    N = preds.size(0)\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k + 1) * (N // splits), :]\n",
    "        py = torch.mean(part, dim=0)\n",
    "        scores = torch.exp(torch.sum(part * torch.log(part / py[None, :]), dim=1))\n",
    "        split_scores.append(scores.mean().item())\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "# Frechet Inception Distance\n",
    "def calculate_fid(real_images, fake_images):\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).eval().to(real_images.device)\n",
    "\n",
    "    def get_activations(images):\n",
    "        images_resized = torch.nn.functional.interpolate(images, size=(299, 299), mode='bilinear')\n",
    "        with torch.no_grad():\n",
    "            activations = []\n",
    "            for img_batch in torch.split(images_resized, 32):\n",
    "                act = inception_model(img_batch).detach()\n",
    "                activations.append(act)\n",
    "        return torch.cat(activations, dim=0).cpu().numpy()\n",
    "\n",
    "    real_activations = get_activations(real_images)\n",
    "    fake_activations = get_activations(fake_images)\n",
    "\n",
    "    mu_real, sigma_real = real_activations.mean(axis=0), np.cov(real_activations, rowvar=False)\n",
    "    mu_fake, sigma_fake = fake_activations.mean(axis=0), np.cov(fake_activations, rowvar=False)\n",
    "\n",
    "    diff = mu_real - mu_fake\n",
    "    covmean = sqrtm(sigma_real.dot(sigma_fake))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    return float(diff.dot(diff) + np.trace(sigma_real + sigma_fake - 2 * covmean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a76c235e-63e2-4257-ba8f-0e055075023c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_and_save_images(generator, epoch, noise_dim, text_dim, device, num_examples=10):\n",
    "    generator.eval()\n",
    "    noise = torch.randn(num_examples, noise_dim).to(device)\n",
    "    text = torch.randn(num_examples, text_dim).to(device)\n",
    "    fake_images = generator(noise, text).cpu().detach()\n",
    "\n",
    "    fake_images = (fake_images + 1) / 2  # Rescale to [0, 1]\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_examples):\n",
    "        plt.subplot(1, num_examples, i + 1)\n",
    "        plt.imshow(fake_images[i].permute(1, 2, 0).numpy())\n",
    "        plt.axis(\"off\")\n",
    "    plt.savefig(f\"generated_images_epoch_{epoch}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb84c14-734a-49fc-bdc6-446ea22b54d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Gen Loss: 2.62575626373291 | Disc Loss: 0.7526130676269531\n",
      "Epoch [2/50] | Gen Loss: 2.7964208126068115 | Disc Loss: 0.7040140628814697\n",
      "Epoch [3/50] | Gen Loss: 2.083345413208008 | Disc Loss: 0.6548295021057129\n",
      "Epoch [4/50] | Gen Loss: 2.061908721923828 | Disc Loss: 0.6509606838226318\n",
      "Epoch [5/50] | Gen Loss: 2.0748696327209473 | Disc Loss: 0.6652166843414307\n",
      "Epoch [6/50] | Gen Loss: 1.9977624416351318 | Disc Loss: 0.6566369533538818\n",
      "Epoch [7/50] | Gen Loss: 2.1267926692962646 | Disc Loss: 0.6509142518043518\n",
      "Epoch [8/50] | Gen Loss: 1.266461968421936 | Disc Loss: 1.1185492277145386\n",
      "Epoch [9/50] | Gen Loss: 1.9870193004608154 | Disc Loss: 0.6522029638290405\n",
      "Epoch [10/50] | Gen Loss: 2.0760927200317383 | Disc Loss: 0.650847315788269\n",
      "Epoch [11/50] | Gen Loss: 2.0695438385009766 | Disc Loss: 0.6502892971038818\n",
      "Epoch [12/50] | Gen Loss: 2.1052074432373047 | Disc Loss: 0.6511006355285645\n",
      "Epoch [13/50] | Gen Loss: 2.037440776824951 | Disc Loss: 0.6516380906105042\n",
      "Epoch [14/50] | Gen Loss: 2.048128366470337 | Disc Loss: 0.6509713530540466\n",
      "Epoch [15/50] | Gen Loss: 1.8217729330062866 | Disc Loss: 1.0518169403076172\n",
      "Epoch [16/50] | Gen Loss: 2.4402472972869873 | Disc Loss: 0.6956722140312195\n",
      "Epoch [17/50] | Gen Loss: 1.8580046892166138 | Disc Loss: 0.699120819568634\n",
      "Epoch [18/50] | Gen Loss: 2.2947263717651367 | Disc Loss: 0.6964067816734314\n",
      "Epoch [19/50] | Gen Loss: 3.988267183303833 | Disc Loss: 0.9490209221839905\n",
      "Epoch [20/50] | Gen Loss: 2.2895171642303467 | Disc Loss: 0.7407037615776062\n",
      "Epoch [21/50] | Gen Loss: 0.9774087071418762 | Disc Loss: 0.9929510354995728\n",
      "Epoch [22/50] | Gen Loss: 2.1909992694854736 | Disc Loss: 0.7537760734558105\n",
      "Epoch [23/50] | Gen Loss: 2.053133010864258 | Disc Loss: 0.7069993019104004\n",
      "Epoch [24/50] | Gen Loss: 2.4702889919281006 | Disc Loss: 0.67806077003479\n",
      "Epoch [25/50] | Gen Loss: 2.12477445602417 | Disc Loss: 0.6537297964096069\n",
      "Epoch [26/50] | Gen Loss: 2.322619676589966 | Disc Loss: 0.6846247315406799\n",
      "Epoch [27/50] | Gen Loss: 1.5678589344024658 | Disc Loss: 0.7351670265197754\n",
      "Epoch [28/50] | Gen Loss: 2.6159512996673584 | Disc Loss: 0.6948575973510742\n",
      "Epoch [29/50] | Gen Loss: 1.981466293334961 | Disc Loss: 0.660659909248352\n",
      "Epoch [30/50] | Gen Loss: 2.0852084159851074 | Disc Loss: 0.6869514584541321\n",
      "Epoch [31/50] | Gen Loss: 1.673185110092163 | Disc Loss: 0.6711868643760681\n",
      "Epoch [32/50] | Gen Loss: 2.6695144176483154 | Disc Loss: 0.6828588247299194\n",
      "Epoch [33/50] | Gen Loss: 2.9730677604675293 | Disc Loss: 0.7029620409011841\n",
      "Epoch [34/50] | Gen Loss: 1.9152095317840576 | Disc Loss: 0.6691972017288208\n",
      "Epoch [35/50] | Gen Loss: 3.8837602138519287 | Disc Loss: 0.7277504205703735\n",
      "Epoch [36/50] | Gen Loss: 2.001826763153076 | Disc Loss: 0.6987350583076477\n",
      "Epoch [37/50] | Gen Loss: 2.483713388442993 | Disc Loss: 1.5462806224822998\n",
      "Epoch [38/50] | Gen Loss: 2.039377212524414 | Disc Loss: 0.6744536757469177\n",
      "Epoch [39/50] | Gen Loss: 0.7869608402252197 | Disc Loss: 0.826906681060791\n",
      "Epoch [40/50] | Gen Loss: 1.7764793634414673 | Disc Loss: 0.7243667244911194\n",
      "Epoch [41/50] | Gen Loss: 1.8686109781265259 | Disc Loss: 0.6714787483215332\n",
      "Epoch [42/50] | Gen Loss: 2.1433775424957275 | Disc Loss: 0.6681864261627197\n",
      "Epoch [43/50] | Gen Loss: 1.9424726963043213 | Disc Loss: 0.6718703508377075\n",
      "Epoch [44/50] | Gen Loss: 2.102233648300171 | Disc Loss: 0.684035062789917\n",
      "Epoch [45/50] | Gen Loss: 2.111912965774536 | Disc Loss: 0.6725782155990601\n",
      "Epoch [46/50] | Gen Loss: 2.35532283782959 | Disc Loss: 0.6682133674621582\n",
      "Epoch [47/50] | Gen Loss: 2.032792329788208 | Disc Loss: 0.664540708065033\n",
      "Epoch [48/50] | Gen Loss: 2.402627944946289 | Disc Loss: 0.6757199764251709\n",
      "Epoch [49/50] | Gen Loss: 1.9727671146392822 | Disc Loss: 0.6598767638206482\n",
      "Epoch [50/50] | Gen Loss: 2.4640846252441406 | Disc Loss: 0.6781888008117676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ldusana/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ldusana/.local/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception Score: 2.4239993572235106 ± 0.23913216295525017\n",
      "FID Score: 994.4297109825263\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "noise_dim = 100\n",
    "text_dim = 119\n",
    "epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(noise_dim, text_dim)\n",
    "discriminator = Discriminator(text_dim)\n",
    "\n",
    "# Train models\n",
    "train(generator, discriminator, dataloader, epochs, noise_dim, text_dim, device)\n",
    "\n",
    "# Generate images and evaluate\n",
    "num_samples = 1000\n",
    "real_images = next(iter(dataloader))[0][:num_samples].to(device)\n",
    "noise = torch.randn(num_samples, noise_dim).to(device)\n",
    "text = torch.randn(num_samples, text_dim).to(device)\n",
    "fake_images = generator(noise, text)\n",
    "\n",
    "# Evaluation metrics\n",
    "mean_is, std_is = inception_score(fake_images)\n",
    "print(f\"Inception Score: {mean_is} ± {std_is}\")\n",
    "\n",
    "fid_score = calculate_fid(real_images, fake_images)\n",
    "print(f\"FID Score: {fid_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
